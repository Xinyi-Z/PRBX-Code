{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install statsmodels==0.12.1"
      ],
      "metadata": {
        "id": "LVu9whYgAXuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit_posthocs"
      ],
      "metadata": {
        "id": "YL3CgVavERJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6Up0orN2weX"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D\n",
        "\n",
        "import warnings\n",
        "import copy\n",
        "from operator import itemgetter\n",
        "\n",
        "from scipy.stats import friedmanchisquare\n",
        "from scikit_posthocs import posthoc_nemenyi, posthoc_nemenyi_friedman, posthoc_conover_friedman"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check whether GPU is available\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "id": "Jq1e230gqSO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data\n",
        "\n",
        "> GDP growth rate, quarterly 1989 Q1 -- 2021 Q3\n",
        "\n",
        "> CPIH, quarterly 1989 Q1 -- 2021 Q3\n",
        "\n",
        "> Unemploment rate, quarterly 1989 Q1 -- 2021 Q3"
      ],
      "metadata": {
        "id": "CJAcFios3AlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(file_name):\n",
        "  \"\"\"\n",
        "  This function takes in time series' file name and return the time series.\n",
        "  :param file_name: the name of the file contains time series.\n",
        "  :return: Series data.\n",
        "  \"\"\"\n",
        "  data = pd.read_csv(file_name)\n",
        "  df = pd.DataFrame(data)\n",
        "  df['Date'] = pd.to_datetime(df['Time'].str.replace(r'(\\d+) (Q\\d)', r'\\1-\\2'), errors='coerce')\n",
        "  data = df.drop(columns=['Time'],axis=1).set_index('Date')\n",
        "  return data"
      ],
      "metadata": {
        "id": "xUxAhQ6rIsfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "gdp = read_file('UK_GDP.csv')\n",
        "inflation = read_file('UK_inflation.csv')\n",
        "unemployment = read_file('UK_unemployment.csv')"
      ],
      "metadata": {
        "id": "3L8MId0BHlfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ADF test"
      ],
      "metadata": {
        "id": "hS-pujpYH1-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adf_test(data):\n",
        "  \"\"\"\n",
        "  This function takes in time series and check for stationarity.\n",
        "  :param data: a time series.\n",
        "  :return: Float p-value.\n",
        "  \"\"\" \n",
        "  data = data.squeeze().dropna() \n",
        "  test = adfuller(data)\n",
        "  output = pd.Series(test[0:2], index=['Test Statistic', 'p-value'])\n",
        "  for key, value in test[4].items():\n",
        "    output['Critical Value %s' % key] = value\n",
        "  return test[1]"
      ],
      "metadata": {
        "id": "h7vGy60tzxgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adf_result = {}\n",
        "\n",
        "gdp_adf = adf_test(gdp)\n",
        "adf_result[\"GDP\"] = gdp_adf\n",
        "if gdp_adf > 0.05:\n",
        "  gdp_diff1 = gdp.diff()\n",
        "  gdp_diff1_adf = adf_test(gdp_diff1)\n",
        "  adf_result[\"GDP after first difference\"] = gdp_diff1_adf\n",
        "\n",
        "inflation_adf = adf_test(inflation)\n",
        "adf_result[\"Inflation\"] = inflation_adf\n",
        "if inflation_adf > 0.05:\n",
        "  inflation_diff1 = inflation.diff()\n",
        "  inflation_diff1_adf = adf_test(inflation_diff1)\n",
        "  adf_result[\"Inflation after first difference\"] = inflation_diff1_adf\n",
        "\n",
        "unemployment_adf = adf_test(unemployment)\n",
        "adf_result[\"Unemployment\"] = unemployment_adf\n",
        "if unemployment_adf > 0.05:\n",
        "  unemployment_diff1 = unemployment.diff()\n",
        "  unemployment_diff1_adf = adf_test(unemployment_diff1)\n",
        "  adf_result[\"Unemployment after first difference\"] = unemployment_diff1_adf\n",
        "\n",
        "adf_result"
      ],
      "metadata": {
        "id": "a8bHYWRYJIEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Normalization"
      ],
      "metadata": {
        "id": "1Yx0BIcFZ7dV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "gdp_scaler = scaler.fit_transform(gdp)\n",
        "gdp_scaler = pd.DataFrame(data=gdp_scaler, index=gdp.index)\n",
        "\n",
        "inflation_scaler = scaler.fit_transform(inflation)\n",
        "inflation_scaler = pd.DataFrame(data=inflation_scaler, index=inflation.index)\n",
        "\n",
        "unemployment_scaler = scaler.fit_transform(unemployment)\n",
        "unemployment_scaler = pd.DataFrame(data=unemployment_scaler, index=unemployment.index)"
      ],
      "metadata": {
        "id": "Le2I94M0tlis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "ggcoKZ6TR-Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,12))\n",
        "plt.subplot(331)\n",
        "plt.plot(gdp)\n",
        "plt.subplot(332)\n",
        "plt.plot(gdp_diff1)\n",
        "plt.subplot(333)\n",
        "plt.plot(gdp_scaler)"
      ],
      "metadata": {
        "id": "GfTkc6786-Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,12))\n",
        "plt.subplot(221)\n",
        "plt.plot(inflation)\n",
        "plt.subplot(222)\n",
        "plt.plot(inflation_scaler)\n"
      ],
      "metadata": {
        "id": "zijQgYBMDInr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,12))\n",
        "plt.subplot(331)\n",
        "plt.plot(unemployment)\n",
        "plt.subplot(332)\n",
        "plt.plot(unemployment_diff1)\n",
        "plt.subplot(333)\n",
        "plt.plot(unemployment_scaler)"
      ],
      "metadata": {
        "id": "m18XWgvpD3gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seperate data\n",
        "\n",
        "\n",
        "\n",
        "> Train - Validate - Test\n",
        "\n",
        "> Train - Test\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9GTHG9sSaIrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_validate_test_split(data):\n",
        "  \"\"\"\n",
        "  This function takes in time series and split to train, validate and test sets.\n",
        "  :param data: a time series.\n",
        "  :return: Series train, validate and test.\n",
        "  \"\"\"\n",
        "  train_size = int(len(data) * train_decimal)\n",
        "  validate_size = int(len(data) * validate_decimal)\n",
        "  \n",
        "  train = data[:train_size]\n",
        "  validate = data[train_size:train_size+validate_size]\n",
        "  test = data[train_size+validate_size:]\n",
        "  return train, validate, test"
      ],
      "metadata": {
        "id": "G80ULg0WOSWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(data):\n",
        "  \"\"\"\n",
        "  This function takes in time series and split to train and test sets.\n",
        "  :param data: a time series.\n",
        "  :return: Series train and test.\n",
        "  \"\"\"\n",
        "  new_train_size = int(len(data) * new_train_decimal)\n",
        "  new_train = data[:new_train_size]\n",
        "  new_test = data[new_train_size:]\n",
        "  return new_train, new_test"
      ],
      "metadata": {
        "id": "kfd2_UoMDtVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(9)\n",
        "train_decimal = 0.6\n",
        "validate_decimal = 0.2\n",
        "new_train_decimal = 0.8\n",
        "\n",
        "gdp_train_stg1, gdp_validate_stg1, gdp_test_stg1 = train_validate_test_split(gdp_scaler)\n",
        "inflation_train_stg1, inflation_validate_stg1, inflation_test_stg1 = train_validate_test_split(inflation_scaler)\n",
        "unemployment_train_stg1, unemployment_validate_stg1, unemployment_test_stg1 = train_validate_test_split(unemployment_scaler)\n",
        "\n",
        "gdp_train_stg2, gdp_test_stg2 = train_test_split(gdp_scaler)\n",
        "inflation_train_stg2, inflation_test_stg2 = train_test_split(inflation_scaler)\n",
        "unemployment_train_stg2, unemployment_test_stg2 = train_test_split(unemployment_scaler)"
      ],
      "metadata": {
        "id": "dliMexDqKrjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorithms"
      ],
      "metadata": {
        "id": "MyFNFUfNShZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ARIMA"
      ],
      "metadata": {
        "id": "2Ie4N6sK314l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def d_value_choose(data):\n",
        "  \"\"\"\n",
        "  This function takes in time series and decide the d value use in ARIMA model.\n",
        "  :param data: a time series.\n",
        "  :return: Integer d value.\n",
        "  \"\"\"\n",
        "  d_value = np.inf\n",
        "  for i in range(3):\n",
        "    stationary = adf_test(data)\n",
        "    if stationary <= 0.05:\n",
        "      d_value = i\n",
        "      break\n",
        "    else:\n",
        "      data = data.diff()\n",
        "  return d_value"
      ],
      "metadata": {
        "id": "aBizmieWFULI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def arima(train, validate, parameters):\n",
        "  \"\"\"\n",
        "  This function takes in train and validate data as well as parameters and calculate \n",
        "  the RMSE between the predictions and reals values from validate set.\n",
        "  :param train: train set of time series\n",
        "  :param validate: validate set of time series\n",
        "  :param parameters: parameters used as the configuration of model.\n",
        "  :return: Float RMSE value.\n",
        "  \"\"\"\n",
        "  num_logs = parameters[1]\n",
        "  history = []\n",
        "  for x in train.values:\n",
        "    history.append(x)\n",
        "  predictions = []\n",
        "  for t in range(len(validate)):\n",
        "    model = ARIMA(history, order=(num_logs, d_value_choose(train), 0)).fit()\n",
        "    predict = model.forecast()[0]\n",
        "    predictions.append(predict)\n",
        "    valid = validate.values[t]\n",
        "    history.append(valid)\n",
        "  rmse = np.sqrt(mean_squared_error(validate.values, predictions))\n",
        "  predictions = pd.Series(predictions, index=validate.index)\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "HS0iSOL-PxsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Covolutional neural network"
      ],
      "metadata": {
        "id": "5o1i7ZogBlzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_num_logs_split(data, num_logs):\n",
        "  \"\"\"\n",
        "  This function takes in time series data and splits it into x and y values.\n",
        "  :param data:time series dataset\n",
        "  :param num_logs: num_logs is how many values in the time series you need for predicting the future values.\n",
        "  :return: Tuple containing an Array of X values and an Array of y values.\n",
        "  \"\"\"\n",
        "  X, y = [], []\n",
        "  X_date, y_date = [], []\n",
        "  for i in range(len(data)):\n",
        "    end_index = i + num_logs\n",
        "    if end_index > len(data) - 1:\n",
        "      break\n",
        "    log_xs, log_y = data.values.squeeze()[i:end_index], data.values.squeeze()[end_index]\n",
        "    date_xs, date_ys = data.index[i:end_index], data.index[end_index]\n",
        "    X.append(log_xs)\n",
        "    y.append(log_y)\n",
        "    X_date.append(date_xs)\n",
        "    y_date.append(date_ys)\n",
        "  return np.array(X), np.array(y), X_date, y_date"
      ],
      "metadata": {
        "id": "vQDHFYPoNkJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN univariate:\n",
        "\n",
        " \n",
        "\n",
        "> For single time series input.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MxdwU11SBqnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_univariate_stg1(train, validate, test, parameters):\n",
        "  \"\"\"\n",
        "  This function takes in train and validate data as well as parameters to calculate \n",
        "  the RMSE between the predictions and reals values from validate set.\n",
        "  :param train: train set of time series.\n",
        "  :param validate: validate set of time series.\n",
        "  :param test: test set of time series.\n",
        "  :param parameters: parameters used as the configuration of model.\n",
        "  :return: Float RMSE value on validate set and RMSE value on test set.\n",
        "  \"\"\"\n",
        "  num_epochs, num_logs, num_hidden_layers, num_hidden_nodes, activation, optimizer = parameters[0], \\\n",
        "  parameters[1], parameters[2], parameters[3], parameters[4], parameters[5]\n",
        "  X_train, y_train, X_train_date, y_train_date = data_num_logs_split(train, num_logs)\n",
        "  X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "  X_validate, y_validate, X_validate_date, y_validate_date = data_num_logs_split(validate, num_logs)\n",
        "  X_validate = X_validate.reshape((X_validate.shape[0], X_validate.shape[1], 1))\n",
        "  X_test, y_test, X_test_date, y_test_date = data_num_logs_split(test, num_logs)\n",
        "  X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "  cnn_single_model = keras.Sequential()\n",
        "  cnn_single_model.add(Conv1D(filters=64, kernel_size=2, activation=activation, input_shape=(num_logs, 1)))\n",
        "  cnn_single_model.add(MaxPooling1D())\n",
        "  cnn_single_model.add(Flatten())\n",
        "  for layer_index in range(num_hidden_layers):\n",
        "    cnn_single_model.add(Dense(num_hidden_nodes, input_dim=num_logs, activation=activation))\n",
        "  cnn_single_model.add(Dense(1))\n",
        "  cnn_single_model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "  cnn_single_model.fit(X_train, y_train, batch_size=100, epochs=num_epochs, verbose=2)\n",
        "  \n",
        "  y_validate_predict = []\n",
        "  for X_validate_fragment in X_validate:\n",
        "    X_validate_fragment = np.array(X_validate_fragment)\n",
        "    X_validate_fragment = X_validate_fragment.reshape((1, num_logs, 1))\n",
        "    y_predict = cnn_single_model.predict(X_validate_fragment, verbose=0)\n",
        "    y_validate_predict.append(y_predict[0][0])\n",
        "  rmse = np.sqrt(mean_squared_error(y_validate, y_validate_predict))\n",
        "\n",
        "  y_test_predict = []\n",
        "  for X_test_fragment in X_test:\n",
        "    X_test_fragment = np.array(X_test_fragment)\n",
        "    X_test_fragment = X_test_fragment.reshape((1, num_logs, 1))\n",
        "    y_predict = cnn_single_model.predict(X_test_fragment, verbose=0)\n",
        "    y_test_predict.append(y_predict[0][0])\n",
        "  test_rmse = np.sqrt(mean_squared_error(y_test, y_test_predict))\n",
        "\n",
        "  return rmse, test_rmse"
      ],
      "metadata": {
        "id": "jS8LTm9SQwnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_univariate_stg2(train, test, parameters):\n",
        "  \"\"\"\n",
        "  This function takes in train and test data as well as parameters to calculate \n",
        "  the RMSE between the predictions and reals values from test set.\n",
        "  :param train: train set of time series.\n",
        "  :param test: test set of time series.\n",
        "  :param parameters: parameters used as the configuration of model.\n",
        "  :return: Float RMSE value on test set.\n",
        "  \"\"\"\n",
        "  num_epochs, num_logs, num_hidden_layers, num_hidden_nodes, activation, optimizer = parameters[0], \\\n",
        "  parameters[1], parameters[2], parameters[3], parameters[4], parameters[5]\n",
        "  X_train, y_train, X_train_date, y_train_date = data_num_logs_split(train, num_logs)\n",
        "  X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "  X_test, y_test, X_test_date, y_test_date = data_num_logs_split(test, num_logs)\n",
        "  X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "  cnn_single_model = keras.Sequential()\n",
        "  cnn_single_model.add(Conv1D(filters=64, kernel_size=2, activation=activation, input_shape=(num_logs, 1)))\n",
        "  cnn_single_model.add(MaxPooling1D())\n",
        "  cnn_single_model.add(Flatten())\n",
        "  for layer_index in range(num_hidden_layers):\n",
        "    cnn_single_model.add(Dense(num_hidden_nodes, input_dim=num_logs, activation=activation))\n",
        "  cnn_single_model.add(Dense(1))\n",
        "  cnn_single_model.compile(optimizer=optimizer, loss='mse')\n",
        "  cnn_single_model.fit(X_train, y_train, batch_size=100, epochs=num_epochs, verbose=2)\n",
        "  \n",
        "  y_test_predict = []\n",
        "  for X_test_fragment in X_test:\n",
        "    X_test_fragment = np.array(X_test_fragment)\n",
        "    X_test_fragment = X_test_fragment.reshape((1, num_logs, 1))\n",
        "    y_predict = cnn_single_model.predict(X_test_fragment, verbose=0)\n",
        "    y_test_predict.append(y_predict[0][0])\n",
        "  rmse = np.sqrt(mean_squared_error(y_test, y_test_predict))\n",
        "  y_test_predict = pd.Series(y_test_predict, index=y_test_date)\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "xeR73YUlMpHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN multivariate:\n",
        "\n",
        "> For multiple time series input.\n",
        "\n"
      ],
      "metadata": {
        "id": "A_vB0rCbBrG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_multi_stg1(X_train, y_train, X_validate, y_validate, X_test, y_test, parameters):\n",
        "  \"\"\"\n",
        "  This function takes in inputs and outputs of train, validate and test data as well as parameters to \n",
        "  calculate the RMSE between the predictions and reals values from validate and test set.\n",
        "  :param X_train: input from train set of time series.\n",
        "  :param y_train: output from train set of time series.\n",
        "  :param X_validate: input from validate set of time series.\n",
        "  :param y_validate: output from validate set of time series.\n",
        "  :param X_test: input from test set of time series.\n",
        "  :param y_test: output from test set of time series.\n",
        "  :param parameters: parameters used as the configuration of model.\n",
        "  :return: Float RMSE value on validate set and RMSE value on test set.\n",
        "  \"\"\"\n",
        "  num_epochs, num_logs, num_hidden_layers, num_hidden_nodes, activation, optimizer = parameters[0], \\\n",
        "  parameters[1], parameters[2], parameters[3], parameters[4], parameters[5]\n",
        "  \n",
        "  cnn_multiple_model = keras.Sequential()\n",
        "  cnn_multiple_model.add(Conv1D(filters=64, kernel_size=2, activation=activation, input_shape=(num_logs*3, 1)))\n",
        "  cnn_multiple_model.add(MaxPooling1D())\n",
        "  cnn_multiple_model.add(Flatten())\n",
        "\n",
        "  for layer_index in range(num_hidden_layers):\n",
        "    cnn_multiple_model.add(Dense(num_hidden_nodes, input_dim=num_logs*3, activation=activation))\n",
        "  cnn_multiple_model.add(Dense(1))\n",
        "  cnn_multiple_model.compile(optimizer=optimizer, loss='mse')\n",
        "  cnn_multiple_model.fit(X_train, y_train, batch_size=100, epochs=num_epochs, verbose=2)\n",
        "  \n",
        "  y_validate_predict = []\n",
        "  for X_validate_fragment in X_validate:\n",
        "    X_validate_fragment = np.array(X_validate_fragment)\n",
        "    X_validate_fragment = X_validate_fragment.reshape((1, num_logs*3, 1))\n",
        "    y_predict = cnn_multiple_model.predict(X_validate_fragment, verbose=0)\n",
        "    y_validate_predict.append(y_predict[0][0])\n",
        "  rmse = np.sqrt(mean_squared_error(y_validate, y_validate_predict))\n",
        "\n",
        "  y_test_predict = []\n",
        "  for X_test_fragment in X_test:\n",
        "    X_test_fragment = np.array(X_test_fragment)\n",
        "    X_test_fragment = X_test_fragment.reshape((1, num_logs*3, 1))\n",
        "    y_predict = cnn_multiple_model.predict(X_test_fragment, verbose=0)\n",
        "    y_test_predict.append(y_predict[0][0])\n",
        "  test_rmse = np.sqrt(mean_squared_error(y_test, y_test_predict))\n",
        "  return rmse, test_rmse"
      ],
      "metadata": {
        "id": "J1zawVzxS3YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_multivariate_stg1(datasets, parameters):\n",
        "  \"\"\"\n",
        "  This function takes in all train-validate-test sets for time series as well as parameters to \n",
        "  calculate the RMSE between the predictions and reals values from validate and test set.\n",
        "  :param datasets: list of all train-validate-test sets for time series.\n",
        "  :param parameters: parameters used as the configuration of model.\n",
        "  :return: Float RMSE values on all validate sets and RMSE values on all test sets.\n",
        "  \"\"\"\n",
        "  train1, train2, train3, validate1, validate2, validate3, test1, test2, test3 = datasets[0], \\\n",
        "  datasets[1], datasets[2], datasets[3], datasets[4], datasets[5], datasets[6], datasets[7], datasets[8]\n",
        "  num_logs = parameters[1]\n",
        "  \n",
        "  X_train1, y_train1, X_train1_date, y_train1_date = data_num_logs_split(train1, num_logs)\n",
        "  X_train1 = X_train1.reshape((X_train1.shape[0], X_train1.shape[1], 1))\n",
        "  X_train2, y_train2, X_train2_date, y_train2_date = data_num_logs_split(train2, num_logs)\n",
        "  X_train2 = X_train2.reshape((X_train2.shape[0], X_train2.shape[1], 1))\n",
        "  X_train3, y_train3, X_train3_date, y_train3_date = data_num_logs_split(train3, num_logs)\n",
        "  X_train3 = X_train3.reshape((X_train3.shape[0], X_train3.shape[1], 1))\n",
        "  data_combine_X_train = np.concatenate((X_train1, X_train2, X_train3), axis=1)\n",
        "\n",
        "  X_validate1, y_validate1, X_validate1_date, y_validate1_date = data_num_logs_split(validate1, num_logs)\n",
        "  X_validate1 = X_validate1.reshape((X_validate1.shape[0], X_validate1.shape[1], 1))\n",
        "  X_validate2, y_validate2, X_validate2_date, y_validate2_date = data_num_logs_split(validate2, num_logs)\n",
        "  X_validate2 = X_validate2.reshape((X_validate2.shape[0], X_validate2.shape[1], 1))\n",
        "  X_validate3, y_validate3, X_validate3_date, y_validate3_date = data_num_logs_split(validate3, num_logs)\n",
        "  X_validate3 = X_validate3.reshape((X_validate3.shape[0], X_validate3.shape[1], 1))\n",
        "  data_combine_X_validate = np.concatenate((X_validate1, X_validate2, X_validate3), axis=1)\n",
        "\n",
        "  X_test1, y_test1, X_test1_date, y_test1_date = data_num_logs_split(test1, num_logs)\n",
        "  X_test1 = X_test1.reshape((X_test1.shape[0], X_test1.shape[1], 1))\n",
        "  X_test2, y_test2, X_test2_date, y_test2_date = data_num_logs_split(test2, num_logs)\n",
        "  X_test2 = X_test2.reshape((X_test2.shape[0], X_test2.shape[1], 1))\n",
        "  X_test3, y_test3, X_test3_date, y_test3_date = data_num_logs_split(test3, num_logs)\n",
        "  X_test3 = X_test3.reshape((X_test3.shape[0], X_test3.shape[1], 1))\n",
        "  data_combine_X_test = np.concatenate((X_test1, X_test2, X_test3), axis=1)\n",
        "\n",
        "  rmse1, test_rmse1 = cnn_multi_stg1(data_combine_X_train, y_train1, data_combine_X_validate, \\\n",
        "                      y_validate1, data_combine_X_test, y_test1, parameters)\n",
        "  rmse2, test_rmse2 = cnn_multi_stg1(data_combine_X_train, y_train2, data_combine_X_validate, \\\n",
        "                      y_validate2, data_combine_X_test, y_test2, parameters)\n",
        "  rmse3, test_rmse3 = cnn_multi_stg1(data_combine_X_train, y_train3, data_combine_X_validate, \\\n",
        "                      y_validate3, data_combine_X_test, y_test3, parameters)\n",
        "  return rmse1, rmse2, rmse3, test_rmse1, test_rmse2, test_rmse3"
      ],
      "metadata": {
        "id": "afa7U3peSApb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_multi_stg2(X_train, y_train, X_test, y_test, parameters):\n",
        "  \"\"\"\n",
        "  This function takes in inputs and outputs of train and test data as well as parameters to \n",
        "  calculate the RMSE between the predictions and reals values from test set.\n",
        "  :param X_train: input from train set of time series.\n",
        "  :param y_train: output from train set of time series.\n",
        "  :param X_test: input from test set of time series.\n",
        "  :param y_test: output from test set of time series.\n",
        "  :param parameters: parameters used as the configuration of model.\n",
        "  :return: Float RMSE value on test set.\n",
        "  \"\"\"\n",
        "  num_epochs, num_logs, num_hidden_layers, num_hidden_nodes, activation, optimizer = parameters[0], \\\n",
        "  parameters[1], parameters[2], parameters[3], parameters[4], parameters[5]\n",
        "\n",
        "  cnn_multiple_model = keras.Sequential()\n",
        "  cnn_multiple_model.add(Conv1D(filters=64, kernel_size=2, activation=activation, input_shape=(num_logs*3, 1)))\n",
        "  cnn_multiple_model.add(MaxPooling1D())\n",
        "  cnn_multiple_model.add(Flatten())\n",
        "\n",
        "  for layer_index in range(num_hidden_layers):\n",
        "    cnn_multiple_model.add(Dense(num_hidden_nodes, input_dim=num_logs*3, activation=activation))\n",
        "  cnn_multiple_model.add(Dense(1))\n",
        "  cnn_multiple_model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "  cnn_multiple_model.fit(X_train, y_train, batch_size=100, epochs=num_epochs, verbose=2)\n",
        "\n",
        "  y_test_predict= []\n",
        "  for X_test_fragment in X_test:\n",
        "    X_test_fragment = np.array(X_test_fragment)\n",
        "    X_test_fragment = X_test_fragment.reshape((1, num_logs*3, 1))\n",
        "    y_predict = cnn_multiple_model.predict(X_test_fragment, verbose=0)\n",
        "    y_test_predict.append(y_predict[0][0])\n",
        "\n",
        "  rmse = np.sqrt(mean_squared_error(y_test, y_test_predict))\n",
        "\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "RHHxvG73Pcbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_multivariate_stg2(datasets, parameters):\n",
        "  \"\"\"\n",
        "  This function takes in all train and test sets for time series as well as parameters to \n",
        "  calculate the RMSE between the predictions and reals values from validate and test set.\n",
        "  :param datasets: list of all train and test sets for time series.\n",
        "  :param parameters: parameters used as the configuration of model.\n",
        "  :return: Float RMSE values on all test sets.\n",
        "  \"\"\"\n",
        "  train1, train2, train3, test1, test2, test3 = datasets[0], \\\n",
        "  datasets[1], datasets[2], datasets[3], datasets[4], datasets[5]\n",
        "  num_logs = parameters[1]\n",
        "  \n",
        "  X_train1, y_train1, X_train1_date, y_train1_date = data_num_logs_split(train1, num_logs)\n",
        "  X_train1 = X_train1.reshape((X_train1.shape[0], X_train1.shape[1], 1))\n",
        "  X_train2, y_train2, X_train2_date, y_train2_date = data_num_logs_split(train2, num_logs)\n",
        "  X_train2 = X_train2.reshape((X_train2.shape[0], X_train2.shape[1], 1))\n",
        "  X_train3, y_train3, X_train3_date, y_train3_date = data_num_logs_split(train3, num_logs)\n",
        "  X_train3 = X_train3.reshape((X_train3.shape[0], X_train3.shape[1], 1))\n",
        "  data_combine_X_train = np.concatenate((X_train1, X_train2, X_train3), axis=1)\n",
        "\n",
        "  X_test1, y_test1, _, _ = data_num_logs_split(test1, num_logs)\n",
        "  X_test1 = X_test1.reshape((X_test1.shape[0], X_test1.shape[1], 1))\n",
        "  X_test2, y_test2, _, _ = data_num_logs_split(test2, num_logs)\n",
        "  X_test2 = X_test2.reshape((X_test2.shape[0], X_test2.shape[1], 1))\n",
        "  X_test3, y_test3, _, _ = data_num_logs_split(test3, num_logs)\n",
        "  X_test3 = X_test3.reshape((X_test3.shape[0], X_test3.shape[1], 1))\n",
        "  data_combine_X_test = np.concatenate((X_test1, X_test2, X_test3), axis=1)\n",
        "\n",
        "  rmse1 = cnn_multi_stg2(data_combine_X_train, y_train1, data_combine_X_test, y_test1, parameters)\n",
        "  rmse2 = cnn_multi_stg2(data_combine_X_train, y_train2, data_combine_X_test, y_test2, parameters)\n",
        "  rmse3 = cnn_multi_stg2(data_combine_X_train, y_train3, data_combine_X_test, y_test3, parameters)\n",
        "\n",
        "  return rmse1, rmse2, rmse3"
      ],
      "metadata": {
        "id": "5StwXKQaMtXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments\n",
        "\n",
        "> Experiment 1: Vary the number of epochs.\n",
        "\n",
        "> Experiment 2: Vary the number of logs.\n",
        "\n",
        "> Experiment 3: Vary the number of hidden layers.\n",
        "\n",
        "> Experiment 4: Vary the number of nodes in hidden layers.\n",
        "\n",
        "> Experiment 5: Vary the type of activation function.\n",
        "\n",
        "> Experiment 6: Vary the type of optimizer function.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "90NCWAKUTAzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Default Variables"
      ],
      "metadata": {
        "id": "kV4ov6wK4C6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# default parameters\n",
        "default_epochs = 100\n",
        "default_num_logs = 3\n",
        "default_num_hidden_layers = 7\n",
        "default_num_hidden_nodes = 50\n",
        "default_activation = 'tanh'\n",
        "default_optimizer = 'Adam'\n",
        "\n",
        "default_parameters = [default_epochs, default_num_logs, default_num_hidden_layers, default_num_hidden_nodes, default_activation, default_optimizer]"
      ],
      "metadata": {
        "id": "LzPVBSZVSGBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_rmse = itemgetter(8)"
      ],
      "metadata": {
        "id": "C2EYUBl4CaGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets1 = [gdp_train_stg1, inflation_train_stg1, unemployment_train_stg1, \n",
        "        gdp_validate_stg1, inflation_validate_stg1, unemployment_validate_stg1, \n",
        "        gdp_test_stg1, inflation_test_stg1, unemployment_test_stg1]\n",
        "\n",
        "datasets2 = [gdp_train_stg2, inflation_train_stg2, unemployment_train_stg2, gdp_test_stg2, inflation_test_stg2, unemployment_test_stg2]\n",
        "\n",
        "datasets_name = [\"GDP\", \"Inflation\", \"Unemployment\"]"
      ],
      "metadata": {
        "id": "HDT2Xe-NCoG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers = [\"Data\", \"Model\", \"Epochs\", \"Logs\", \"Layers\", \"Nodes\", \"Activitation\", \"Optimizer\", \"RMSE\"]"
      ],
      "metadata": {
        "id": "gVmZJNnJe594"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1: Vary the number of epochs\n",
        "num_epochs_list = [10, 50, 100, 150]\n",
        "\n",
        "# Experiment 2: Vary the number of logs\n",
        "num_logs_list = [3, 7, 11, 15] #[3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "# Experiment 3: Vary the number of hidden layers\n",
        "num_hidden_layers_list = [1, 3, 5, 7, 9]\n",
        "\n",
        "# Experiment 4: Vary the number of nodes in hidden layers\n",
        "num_hidden_nodes_list = [10, 20, 50, 100, 200]\n",
        "\n",
        "# Experiment 5: Vary the type of activation function\n",
        "activation_list = ['relu', 'sigmoid', 'softmax', 'softplus', 'softsign', 'selu', 'tanh', 'elu']\n",
        "\n",
        "# Experiment 6: Vary the type of optimizer function\n",
        "optimizer_list = ['SGD', 'RMSprop', 'Adam', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl']"
      ],
      "metadata": {
        "id": "JNFRcUrXStkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Strategy 1"
      ],
      "metadata": {
        "id": "4HWf6rivFQdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def expt_result_stg1(expt_num, expt_list, datasets, datasets_name, parameters=default_parameters):\n",
        "  \"\"\"\n",
        "  This function takes in settings of experiment and return the result list\n",
        "  :param expt_num: integer of which experiment is taken.\n",
        "  :param expt_list: list contains how to vary the parameter of this experiment.\n",
        "  :param datasets: train-validate-test sets for all time series.\n",
        "  :param datasets_name: name of all time series.\n",
        "  :param parameters: parameters used as the configuration of model.\n",
        "  :return: list contains results of this experiment.\n",
        "  \"\"\"\n",
        "  expt = []\n",
        "  arima_parameter = [np.nan] * int(len(parameters))\n",
        "  train_validate = datasets[:len(datasets_name)*2]\n",
        "  train_test = datasets[:len(datasets_name)] + datasets[-len(datasets_name):]\n",
        "  for i in range(int(len(datasets_name))):\n",
        "    train, validate, test = datasets[i], datasets[i + int(len(datasets_name))], datasets[i + int(len(datasets_name))*2]\n",
        "    if expt_num != 2:\n",
        "      arima_parameter[1] = parameters[1]\n",
        "      arima_rmse = arima(train, validate, arima_parameter)\n",
        "      test_arima_rmse = arima(train, test, arima_parameter)\n",
        "      expt.append([datasets_name[i], 'ARIMA'] + arima_parameter + [arima_rmse, test_arima_rmse])\n",
        "      update_parameters = parameters.copy()\n",
        "      for item in expt_list: \n",
        "        update_parameters[expt_num - 1] = item\n",
        "        cnn_univariate_rmse, test_cnn_univariate_rmse = cnn_univariate_stg1(train, validate, test, update_parameters)\n",
        "        expt.append([datasets_name[i], 'CNN univariate'] + update_parameters + [cnn_univariate_rmse, test_cnn_univariate_rmse])\n",
        "    else:\n",
        "      update_parameters = parameters.copy()\n",
        "      for item in expt_list:\n",
        "        update_parameters[expt_num - 1] = item\n",
        "        arima_parameter[1] = item\n",
        "        arima_rmse = arima(train, validate, arima_parameter)\n",
        "        test_arima_rmse = arima(train, test, arima_parameter)\n",
        "        expt.append([datasets_name[i], 'ARIMA'] + arima_parameter + [arima_rmse, test_arima_rmse])\n",
        "\n",
        "        cnn_univariate_rmse, test_cnn_univariate_rmse = cnn_univariate_stg1(train, validate, test, update_parameters)\n",
        "        expt.append([datasets_name[i], 'CNN univariate'] + update_parameters + [cnn_univariate_rmse, test_cnn_univariate_rmse])        \n",
        "  for item in expt_list:\n",
        "    update_parameters[expt_num - 1] = item      \n",
        "    cnn_multivariate_rmse1, cnn_multivariate_rmse2, cnn_multivariate_rmse3, test_cnn_multivariate_rmse1, \\\n",
        "    test_cnn_multivariate_rmse2, test_cnn_multivariate_rmse3 = cnn_multivariate_stg1(datasets, update_parameters)\n",
        "    cnn_multivariate_rmse = [cnn_multivariate_rmse1, cnn_multivariate_rmse2, cnn_multivariate_rmse3]\n",
        "    test_cnn_multivariate_rmse = [test_cnn_multivariate_rmse1, test_cnn_multivariate_rmse2, test_cnn_multivariate_rmse3]\n",
        "    for i in range(int(len(datasets_name))):\n",
        "      expt.append([datasets_name[i], 'CNN multivariate'] + update_parameters + [cnn_multivariate_rmse[i], test_cnn_multivariate_rmse[i]])\n",
        "  return expt"
      ],
      "metadata": {
        "id": "qytOKbe8RwjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expt_sorted_models_stg1(expt):\n",
        "  \"\"\"\n",
        "  This function takes in a list contains the result of an experiment.\n",
        "  :param expt: list contains the result of an experiment.\n",
        "  :return: sorted list of all models.\n",
        "  \"\"\"\n",
        "  rmse_dict = {}\n",
        "  for i in range(len(expt)):\n",
        "    dict_key = str(expt[i][1:-2])\n",
        "    if dict_key in rmse_dict.keys():\n",
        "      rmse_dict[dict_key].append([expt[i][8], expt[i][9]])\n",
        "    else:\n",
        "      rmse_dict[dict_key] = [[expt[i][8], expt[i][9]]]  \n",
        "  average_rmse, average_test_rmse = {}, {}\n",
        "  name_of_models = {}\n",
        "  count = 0\n",
        "  for key in rmse_dict:\n",
        "    model_rmse, model_test_rmse = [], []\n",
        "    for j in range(len(rmse_dict[key])):\n",
        "      model_rmse.append(rmse_dict[key][j][0])\n",
        "      model_test_rmse.append(rmse_dict[key][j][1])\n",
        "    average_rmse[count] = np.mean(model_rmse)\n",
        "    average_test_rmse[count] = np.mean(model_test_rmse)\n",
        "    name_of_models[count] = key\n",
        "    count += 1 \n",
        "  sorted_models = []\n",
        "  for key in name_of_models:\n",
        "    sorted_models.append([key, average_rmse[key], average_test_rmse[key], name_of_models[key]])\n",
        "  final_sorted_models = sorted(sorted_models, key=itemgetter(1)) \n",
        "  return final_sorted_models"
      ],
      "metadata": {
        "id": "VZ255Qov3rxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expt_best_print(sorted_models, best_num, summary=False):\n",
        "  \"\"\"\n",
        "  This function takes in a sorted list, the number to print and whether\n",
        "  the sorted list is the summary list to print the best_num best models.\n",
        "  :param sorted_models: sorted list contains mean RMSE for each model.\n",
        "  :param best_num: the number of model to print.\n",
        "  :param summary: whether the sorted list is the summary list.\n",
        "  :return:\n",
        "  \"\"\"\n",
        "  for algo in [\"ARIMA\", \"CNN univariate\", \"CNN multivariate\"]:\n",
        "    count = 0\n",
        "    best_model_index = []\n",
        "    for i in range(len(sorted_models)):\n",
        "      model_parameter = sorted_models[i][3][2:-2].replace(\"'\", '').split(',')\n",
        "      if summary:\n",
        "        if model_parameter[0] == algo and (model_parameter[1] == \" nan\" or int(model_parameter[1]) == 100):\n",
        "          best_model_index.append(i)\n",
        "          count += 1\n",
        "          if count == best_num:\n",
        "            break\n",
        "      else:\n",
        "        if model_parameter[0] == algo:\n",
        "          best_model_index.append(i)\n",
        "          count += 1\n",
        "          if count == best_num:\n",
        "            break\n",
        "    for index in best_model_index:\n",
        "      print(\"The best {} {}: {}, RMSE = {}, Test RMSE = {}\".format(algo, index+1, sorted_models[index][3], \\\n",
        "                sorted_models[index][1], sorted_models[index][2]))\n",
        "  return"
      ],
      "metadata": {
        "id": "8H9Rx3ylrQJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments using the first strategy"
      ],
      "metadata": {
        "id": "AUw0PHCbS00w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expt1_stg1 = expt_result_stg1(1, num_epochs_list, datasets1, datasets_name, parameters=default_parameters)\n",
        "expt2_stg1 = expt_result_stg1(2, num_logs_list, datasets1, datasets_name, parameters=default_parameters)\n",
        "expt3_stg1 = expt_result_stg1(3, num_hidden_layers_list, datasets1, datasets_name, parameters=default_parameters)\n",
        "expt4_stg1 = expt_result_stg1(4, num_hidden_nodes_list, datasets1, datasets_name, parameters=default_parameters)\n",
        "expt5_stg1 = expt_result_stg1(5, activation_list, datasets1, datasets_name, parameters=default_parameters)\n",
        "expt6_stg1 = expt_result_stg1(6, optimizer_list, datasets1, datasets_name, parameters=default_parameters)"
      ],
      "metadata": {
        "id": "SHR2ELPvH00X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expt1_sorted_models_stg1 = expt_sorted_models_stg1(expt1_stg1)\n",
        "expt2_sorted_models_stg1 = expt_sorted_models_stg1(expt2_stg1)\n",
        "expt3_sorted_models_stg1 = expt_sorted_models_stg1(expt3_stg1)\n",
        "expt4_sorted_models_stg1 = expt_sorted_models_stg1(expt4_stg1)\n",
        "expt5_sorted_models_stg1 = expt_sorted_models_stg1(expt5_stg1)\n",
        "expt6_sorted_models_stg1 = expt_sorted_models_stg1(expt6_stg1)\n",
        "\n",
        "stg1 = expt1_stg1 + expt2_stg1 + expt3_stg1 + expt4_stg1 + expt5_stg1 + expt6_stg1\n",
        "stg1_sorted_models = expt_sorted_models_stg1(stg1)"
      ],
      "metadata": {
        "id": "WBzAESVAeINV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Experiment 1:\")\n",
        "expt_best_print(expt1_sorted_models_stg1, 1)\n",
        "print(\"\\n\\nExperiment 2:\")\n",
        "expt_best_print(expt2_sorted_models_stg1, 1)\n",
        "print(\"\\n\\nExperiment 3:\")\n",
        "expt_best_print(expt3_sorted_models_stg1, 1)\n",
        "print(\"\\n\\nExperiment 4:\")\n",
        "expt_best_print(expt4_sorted_models_stg1, 1)\n",
        "print(\"\\n\\nExperiment 5:\")\n",
        "expt_best_print(expt5_sorted_models_stg1, 1)\n",
        "print(\"\\n\\nExperiment 6:\")\n",
        "expt_best_print(expt6_sorted_models_stg1, 1)\n",
        "print(\"\\n\\nExperiment Summary:\")\n",
        "expt_best_print(stg1_sorted_models, 1, summary=True)"
      ],
      "metadata": {
        "id": "H0OQvqCPW_3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Strategy 2"
      ],
      "metadata": {
        "id": "8h_rAbCNFLbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def expt_result_stg2(expt_num, expt_list, datasets, datasets_name, parameters=default_parameters):\n",
        "  \"\"\"\n",
        "  This function takes in settings of experiment and return the result list\n",
        "  :param expt_num: integer of which experiment is taken.\n",
        "  :param expt_list: list contains how to vary the parameter of this experiment.\n",
        "  :param datasets: train and test sets for all time series.\n",
        "  :param datasets_name: name of all time series.\n",
        "  :param parameters: parameters used as the configuration of model.\n",
        "  :return: list contains results of this experiment.\n",
        "  \"\"\"\n",
        "  expt = []\n",
        "  arima_parameter = [np.nan] * int(len(parameters))\n",
        "\n",
        "  for i in range( int( len(datasets_name) ) ):\n",
        "    train, test = datasets[i], datasets[i + int(len(datasets_name))]\n",
        "\n",
        "    if expt_num != 2:\n",
        "      arima_parameter[1] = parameters[1]\n",
        "      arima_rmse = arima(train, test, arima_parameter)\n",
        "      expt.append([datasets_name[i], 'ARIMA'] + arima_parameter + [arima_rmse])\n",
        "\n",
        "      update_parameters = parameters.copy()\n",
        "      for item in expt_list: \n",
        "        update_parameters[expt_num - 1] = item\n",
        "        \n",
        "        cnn_univariate_rmse = cnn_univariate_stg2(train, test, update_parameters)\n",
        "        expt.append([datasets_name[i], 'CNN univariate'] + update_parameters + [cnn_univariate_rmse])\n",
        "    else:\n",
        "      update_parameters = parameters.copy()\n",
        "      for item in expt_list:\n",
        "        update_parameters[expt_num - 1] = item\n",
        "\n",
        "        arima_parameter[1] = item\n",
        "        arima_rmse = arima(train, test, arima_parameter)\n",
        "        expt.append([datasets_name[i], 'ARIMA'] + arima_parameter + [arima_rmse])\n",
        "\n",
        "        cnn_univariate_rmse = cnn_univariate_stg2(train, test, update_parameters)\n",
        "        expt.append([datasets_name[i], 'CNN univariate'] + update_parameters + [cnn_univariate_rmse])\n",
        "  \n",
        "  for item in expt_list:\n",
        "    update_parameters[expt_num - 1] = item      \n",
        "    cnn_multivariate_rmse1, cnn_multivariate_rmse2, cnn_multivariate_rmse3 = \\\n",
        "    cnn_multivariate_stg2(datasets, update_parameters)\n",
        "    cnn_multivariate_rmse = [cnn_multivariate_rmse1, cnn_multivariate_rmse2, cnn_multivariate_rmse3]\n",
        "    for i in range(int(len(datasets_name))):\n",
        "      expt.append([datasets_name[i], 'CNN multivariate'] + update_parameters + [cnn_multivariate_rmse[i]])\n",
        "\n",
        "  return expt"
      ],
      "metadata": {
        "id": "3o4EOf3KQAP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expt_sorted_models_stg2(expt):\n",
        "  \"\"\"\n",
        "  This function takes in a list contains the result of an experiment.\n",
        "  :param expt: list contains the result of an experiment.\n",
        "  :return: list contains rmse value for each model and a sorted list of all models.\n",
        "  \"\"\"\n",
        "  rmse_dict = {}\n",
        "  for i in range(len(expt)):\n",
        "    dict_key = str(expt[i][1:-1])\n",
        "    if dict_key in rmse_dict.keys():\n",
        "      if expt[i][8] not in rmse_dict[dict_key]:\n",
        "        rmse_dict[dict_key].append(expt[i][8])\n",
        "    else:\n",
        "      rmse_dict[dict_key] = [expt[i][8]]  \n",
        "  models_rmse = [] \n",
        "  name_of_models = {}\n",
        "  count = 0\n",
        "  for key in rmse_dict:\n",
        "    models_rmse.append(rmse_dict[key])\n",
        "    name_of_models[count] = key\n",
        "    count += 1  \n",
        "  rmse_values = [*models_rmse]\n",
        "  average_rmse = [np.mean(x) for x in rmse_values]  \n",
        "  sorted_models = []\n",
        "  for key in name_of_models:\n",
        "    sorted_models.append([key,average_rmse[key], name_of_models[key]])\n",
        "  get_rmse = itemgetter(1)\n",
        "  final_sorted_models = sorted(sorted_models, key=get_rmse)   \n",
        "  return models_rmse, final_sorted_models"
      ],
      "metadata": {
        "id": "xtWQmxBLDfhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expt_datasets(expt, expt_num):\n",
        "  \"\"\"\n",
        "  This function takes in a list contains the result of an experiment and the experiment number\n",
        "  to return experiment number, how the variable varying, the mean RMSE for each algorithm.\n",
        "  :param expt: list contains the result of an experiment.\n",
        "  :param expt_num: the number of experiment.\n",
        "  :return: experiment number, lists contains how the variable varying, lists contains the mean RMSE for each algorithm.\n",
        "  \"\"\"\n",
        "  labels, arima_rmse, cnn_univariate_rmse, cnn_multivariate_rmse = [], {}, {}, {}\n",
        "  for i in range(len(expt)):\n",
        "    if expt[i][1] != \"ARIMA\" and expt[i][expt_num + 1] not in labels:\n",
        "      labels.append(expt[i][expt_num + 1])\n",
        "    if expt[i][1] == 'ARIMA':\n",
        "      if expt[i][expt_num + 1] in arima_rmse.keys():\n",
        "        arima_rmse[expt[i][expt_num + 1]].append(expt[i][8])\n",
        "      else:\n",
        "        arima_rmse[expt[i][expt_num + 1]] = [expt[i][8]]\n",
        "    elif expt[i][1] == 'CNN univariate':\n",
        "      if expt[i][expt_num + 1] in cnn_univariate_rmse.keys():\n",
        "        cnn_univariate_rmse[expt[i][expt_num + 1]].append(expt[i][8])\n",
        "      else:\n",
        "        cnn_univariate_rmse[expt[i][expt_num + 1]] = [expt[i][8]]\n",
        "    else:\n",
        "      if expt[i][expt_num + 1] in cnn_multivariate_rmse.keys():\n",
        "        cnn_multivariate_rmse[expt[i][expt_num + 1]].append(expt[i][8])\n",
        "      else:\n",
        "        cnn_multivariate_rmse[expt[i][expt_num + 1]] = [expt[i][8]]\n",
        "  for rmse_dict in [arima_rmse, cnn_univariate_rmse, cnn_multivariate_rmse]:\n",
        "    for k in rmse_dict.keys():\n",
        "      v = list(rmse_dict[k])\n",
        "      mean_rmse = sum(v) / len(v)\n",
        "      rmse_dict[k] = mean_rmse \n",
        "  return expt_num, labels, arima_rmse, cnn_univariate_rmse, cnn_multivariate_rmse"
      ],
      "metadata": {
        "id": "NT22pTIFvWuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expt_plot(lists):\n",
        "  \"\"\"\n",
        "  This function takes in results of the expt_datasets(expt, expt_num) function and plot them.\n",
        "  :param lists: results of the expt_datasets(expt, expt_num) function.\n",
        "  :return:\n",
        "  \"\"\"  \n",
        "  expt_num, labels, arima_rmse, cnn_univariate_rmse, cnn_multivariate_rmse = lists[0], \\\n",
        "  lists[1], lists[2], lists[3], lists[4]\n",
        "  expt_name = headers[2:-1]\n",
        "  arima_rmse = list(arima_rmse.values()) * len(cnn_univariate_rmse) \\\n",
        "  if len(arima_rmse) == 1 else list(arima_rmse.values())\n",
        "  cnn_univariate_rmse, cnn_multivariate_rmse = list(cnn_univariate_rmse.values()), \\\n",
        "  list(cnn_multivariate_rmse.values())\n",
        "\n",
        "  plt.figure(figsize=(8,4))\n",
        "  plt.plot(arima_rmse, color='red', label='ARIMA')\n",
        "  plt.plot(cnn_univariate_rmse, color='green', label='CNN univariate')\n",
        "  plt.plot(cnn_multivariate_rmse, color='blue', label='CNN multivariate')\n",
        "  plt.legend()\n",
        "  plt.xticks(ticks=np.arange(len(labels)), labels=labels)\n",
        "  plt.grid()\n",
        "  plt.xlabel(expt_name[expt_num-1])\n",
        "  plt.ylabel(\"RMSE\")\n",
        "  plt.title(\"Varying \"+expt_name[expt_num-1])"
      ],
      "metadata": {
        "id": "DIwPXT6UKwtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expt_friedman_conover(expt, expt_num):\n",
        "  \"\"\"\n",
        "  This function takes in a list contains the result of an experiment and the number of experiment\n",
        "  to print the result of Friedman test and Conover test if the p-value of Friedman test is less\n",
        "  than 0.05.\n",
        "  :param expt: list contains the result of an experiment.\n",
        "  :param expt_num: the number of experiment.\n",
        "  :return:\n",
        "  \"\"\" \n",
        "  dataset_friedman, final_sorted_models = expt_sorted_models_stg2(expt)\n",
        "  for i in range(len(dataset_friedman)):\n",
        "    if len(dataset_friedman[i]) != 3:\n",
        "      value = np.mean(dataset_friedman[i])\n",
        "      dataset_friedman[i] = [value] * 3\n",
        "  rmse_values = [*dataset_friedman]\n",
        "  transpose_rmse_values = np.array(rmse_values).T.tolist()\n",
        "\n",
        "  print(\"Printing out the complete data passed to friedman test: \", dataset_friedman)\n",
        "  stat, p = friedmanchisquare(*dataset_friedman)\n",
        "  print(\"Friedman test : \")\n",
        "  print('p-value = %.5f' % (p))\n",
        "  alpha = 0.05\n",
        "  if p > alpha:\n",
        "    print('Fail to reject H0.')\n",
        "  else:\n",
        "    print('Reject H0.')\n",
        "\n",
        "    # The post hoc Conover test.\n",
        "    average_rmse = [np.mean(x) for x in rmse_values]\n",
        "    conover = posthoc_conover_friedman(transpose_rmse_values)\n",
        "    pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "    print(\"conover :\\n\", conover)\n",
        "\n",
        "    # Locate the the significant difference.\n",
        "    for i in range(conover.shape[0]):\n",
        "      for j in range(i+1, conover.shape[1]):\n",
        "        if conover.iloc[i,j] < alpha:\n",
        "          print(\"\\n | CONOVER |Found indication of difference (p = \", conover.iloc[i,j],\") between network \", i, \" and \",j)\n",
        "\n",
        "    print(\"\\nSorted models in order of RMSE : \\n\")\n",
        "    for model in final_sorted_models:\n",
        "      print(\"Model {0} : mean RMSE = {1:.5f} for {2}\".format(*model))\n",
        "  return"
      ],
      "metadata": {
        "id": "JatsIdCz91Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Expermiments using the second strategy"
      ],
      "metadata": {
        "id": "HPJmqh1oTG31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expt1_stg2 = expt_result_stg2(1, num_epochs_list, datasets2, datasets_name, parameters=default_parameters)\n",
        "expt2_stg2 = expt_result_stg2(2, num_logs_list, datasets2, datasets_name, parameters=default_parameters)\n",
        "expt3_stg2 = expt_result_stg2(3, num_hidden_layers_list, datasets2, datasets_name, parameters=default_parameters)\n",
        "expt4_stg2 = expt_result_stg2(4, num_hidden_nodes_list, datasets2, datasets_name, parameters=default_parameters)\n",
        "expt5_stg2 = expt_result_stg2(5, activation_list, datasets2, datasets_name, parameters=default_parameters)\n",
        "expt6_stg2 = expt_result_stg2(6, optimizer_list, datasets2, datasets_name, parameters=default_parameters)"
      ],
      "metadata": {
        "id": "GNlcNaT9oXx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expt_plot(expt_datasets(expt1_stg2, 1))\n",
        "expt_friedman_conover(expt1_stg2, 1)"
      ],
      "metadata": {
        "id": "e4JEAIOfus9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expt_plot(expt_datasets(expt2_stg2, 2))\n",
        "expt_friedman_conover(expt2_stg2, 2)"
      ],
      "metadata": {
        "id": "YASkByuI1Dza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expt_plot(expt_datasets(expt3_stg2, 3))\n",
        "expt_friedman_conover(expt3_stg2, 3)"
      ],
      "metadata": {
        "id": "Gp1Rkf9B1Ilk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expt_plot(expt_datasets(expt4_stg2, 4))\n",
        "expt_friedman_conover(expt4_stg2, 4)"
      ],
      "metadata": {
        "id": "AHCl67ZL1NUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expt_plot(expt_datasets(expt5_stg2, 5))\n",
        "expt_friedman_conover(expt5_stg2, 5)"
      ],
      "metadata": {
        "id": "Z7Qqj3tu1Rtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expt_plot(expt_datasets(expt6_stg2, 6))\n",
        "expt_friedman_conover(expt6_stg2, 6)"
      ],
      "metadata": {
        "id": "C-b_mFxm1Xb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search"
      ],
      "metadata": {
        "id": "rlRya90DZoUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_stg2_sorted_models_epoch_select(sorted_rmse, sorted_models, length):\n",
        "  \"\"\"\n",
        "  This function takes in a sorted rmse list, a sorted model list, the number of\n",
        "  epochs and select length best models return a list contains length best rmse \n",
        "  and a list contains length best models.\n",
        "  :param sorted_rmse: sorted list contains RMSE for each model as a list.\n",
        "  :param sorted_models: sorted list contains mean RMSE for each model.\n",
        "  :param length: the number of models to select.\n",
        "  :return: a list contains length best rmse and a list contains length best models.\n",
        "  \"\"\"\n",
        "  stg2_rmse_select = []\n",
        "  stg2_models_select = []\n",
        "  count = 0\n",
        "  for i in range(len(sorted_models)):\n",
        "    algo = sorted_models[i][2][2:-2].replace(\"'\", '').split(',')\n",
        "    if algo[0] == \"CNN univariate\" or algo[0] == \"CNN multivariate\":\n",
        "      stg2_rmse_select.append(sorted_rmse[i])\n",
        "      stg2_models_select.append(sorted_models[i])\n",
        "      count += 1\n",
        "    if count == length:\n",
        "      break\n",
        "  return stg2_rmse_select, stg2_models_select"
      ],
      "metadata": {
        "id": "TE0bOup2YuxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_stg2 = []\n",
        "arima_parameters, cnn_parameters = [], []\n",
        "arima_empty_parameter = [np.nan] * 6\n",
        "for log in [3,7]:\n",
        "  arima_parameter = arima_empty_parameter.copy()\n",
        "  arima_parameter[1] = log\n",
        "  arima_parameters.append(arima_parameter)\n",
        "  for layer in [1,3]:\n",
        "    for node in [50,100]:\n",
        "      for activation in ['relu','tanh']:\n",
        "        for optimizer in ['SGD','Adam']:\n",
        "          cnn_parameters.append([100, log, layer, node, activation, optimizer])"
      ],
      "metadata": {
        "id": "WyMmbaUa41ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(int(len(datasets_name))):\n",
        "  train, test = datasets2[i], datasets2[i + int(len(datasets_name))]\n",
        "    \n",
        "  for arima_parameter in arima_parameters:\n",
        "    arima_rmse = arima(train, test, arima_parameter)\n",
        "    grid_stg2.append([datasets_name[i], 'ARIMA'] + arima_parameter + [arima_rmse])\n",
        "\n",
        "  for cnn_parameter in cnn_parameters:\n",
        "    cnn_univariate_rmse = cnn_univariate_stg2(train, test, cnn_parameter)\n",
        "    grid_stg2.append([datasets_name[i], 'CNN univariate'] + cnn_parameter + [cnn_univariate_rmse])\n",
        "\n",
        "for cnn_parameter in cnn_parameters:           \n",
        "  cnn_multivariate_rmse1, cnn_multivariate_rmse2, cnn_multivariate_rmse3 = \\\n",
        "  cnn_multivariate_stg2(datasets2, cnn_parameter)\n",
        "  cnn_multivariate_rmse = [cnn_multivariate_rmse1, cnn_multivariate_rmse2, cnn_multivariate_rmse3]\n",
        "  for i in range(int(len(datasets_name))):\n",
        "    grid_stg2.append([datasets_name[i], 'CNN multivariate'] + cnn_parameter + [cnn_multivariate_rmse[i]])"
      ],
      "metadata": {
        "id": "NllCGeWPw9ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_stg2_sorted_rmse, grid_stg2_sorted_models = expt_sorted_models_stg2(grid_stg2)\n",
        "grid_best_10_cnn_rmse, grid_best_10_cnn_models = \\\n",
        "grid_stg2_sorted_models_epoch_select(grid_stg2_sorted_rmse, grid_stg2_sorted_models, 10)\n",
        "print(\"\\nSorted models in order of RMSE : \\n\")\n",
        "for model in grid_best_10_cnn_models:\n",
        "  print(\"Model {0} : mean RMSE = {1:.5f} for {2}\".format(*model))"
      ],
      "metadata": {
        "id": "E2Kmr0on8jOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(grid_best_10_cnn_rmse)):\n",
        "  if len(grid_best_10_cnn_rmse[i]) != 3:\n",
        "    value = np.mean(grid_best_10_cnn_rmse[i])\n",
        "    grid_best_10_cnn_rmse[i] = [value] * 3\n",
        "grid_rmse_values = [*grid_best_10_cnn_rmse]\n",
        "\n",
        "# compare samples\n",
        "print(\"Printing out the complete data passed to friedman test: \", grid_best_10_cnn_rmse)\n",
        "stat, p = friedmanchisquare(*grid_best_10_cnn_rmse)\n",
        "print(\"Friedman test : \")\n",
        "print('p-value = %.5f' % (p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "  print('Fail to reject H0.')\n",
        "else:\n",
        "  print('Reject H0.')"
      ],
      "metadata": {
        "id": "xnT0k-uOnR6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(grid_stg2_sorted_models)):\n",
        "  algo = grid_stg2_sorted_models[i][2][2:-2].replace(\"'\", '').split(',')\n",
        "  if algo[0] == \"ARIMA\":\n",
        "    grid_best_arima_index = i\n",
        "    break\n",
        "grid_best_arima_rmse = grid_stg2_sorted_rmse[grid_best_arima_index]\n",
        "print('The best ARIMA model is:\\n', grid_stg2_sorted_models[grid_best_arima_index])"
      ],
      "metadata": {
        "id": "_sugkAEiZjs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_best_10_cnn_rmse_with_arima = grid_best_10_cnn_rmse.copy()\n",
        "grid_best_10_cnn_rmse_with_arima.append(grid_best_arima_rmse)\n",
        "for i in range(len(grid_best_10_cnn_rmse_with_arima)):\n",
        "  if len(grid_best_10_cnn_rmse_with_arima[i]) != 3:\n",
        "    value = np.mean(grid_best_10_cnn_rmse_with_arima[i])\n",
        "    grid_best_10_cnn_rmse_with_arima[i] = [value] * 3\n",
        "grid_rmse_values = [*grid_best_10_cnn_rmse_with_arima]\n",
        "\n",
        "# compare samples\n",
        "print(\"Printing out the complete data passed to friedman test: \", grid_rmse_values)\n",
        "stat, p = friedmanchisquare(*grid_rmse_values)\n",
        "print(\"Friedman test : \")\n",
        "print('p-value = %.5f' % (p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "  print('Fail to reject H0.')\n",
        "else:\n",
        "  print('Reject H0.')"
      ],
      "metadata": {
        "id": "25757-zKnyhp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}